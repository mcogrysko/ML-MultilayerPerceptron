{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5da9ea5",
   "metadata": {},
   "source": [
    "### Mike Ogrysko\n",
    "### CS 737 Machine Learning\n",
    "Multilayer Perception implementation\n",
    "- 2 hidden layer neural network implementation\n",
    "- Uses MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de9408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import ranf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae40e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    from numpy import fromfile, uint8\n",
    "    import os\n",
    "    import struct\n",
    "\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = fromfile(lbpath, dtype=uint8)\n",
    "        with open(images_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "            images = fromfile(imgpath, dtype=uint8).reshape(len(labels), 784)\n",
    "            images = ((images / 255.) - .5) * 2\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc640ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows= 60000, columns= 784\n",
      "Rows= 10000, columns= 784\n"
     ]
    }
   ],
   "source": [
    "#training and test sets\n",
    "X_train, y_train = load_mnist('mnist/', kind='train')\n",
    "print(f'Rows= {X_train.shape[0]}, columns= {X_train.shape[1]}')\n",
    "\n",
    "X_test, y_test = load_mnist('mnist/', kind='t10k')\n",
    "print(f'Rows= {X_test.shape[0]}, columns= {X_test.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d90847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get accuracy\n",
    "def get_acc(_y_test, _y_pred):\n",
    "    return ((np.sum(_y_test == _y_pred)).astype(float) / _y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2961040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "class NeuralNetMLP(object):\n",
    "\n",
    "    def __init__(self, n_hidden=30, epochs=300, eta=0.0001, minibatch_size=1, seed=None):\n",
    "        self.random = np.random.RandomState(seed)  # used to randomize weights\n",
    "        self.n_hidden = n_hidden  # size of the hidden layer\n",
    "        self.epochs = epochs  # number of iterations\n",
    "        self.eta = eta  # learning rate\n",
    "        self.minibatch_size = minibatch_size  # size of training batch - 1 would not work\n",
    "\n",
    "    @staticmethod\n",
    "    def onehot(y, n_classes):  # one hot encode the input class y\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot.T\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):  # Eq 1\n",
    "        return 1.0 / (1.0 + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):  # Eq 2\n",
    "        #input to hidden layer 1\n",
    "        z_h_1 = np.dot(X, self.w_h_1)\n",
    "        a_h_1 = self.sigmoid(z_h_1)\n",
    "        #hidden layer 1 to hidden layer 2\n",
    "        z_h_2 = np.dot(a_h_1, self.w_h_2)\n",
    "        a_h_2 = self.sigmoid(z_h_2)\n",
    "        #hidden layer 2 to output\n",
    "        z_out = np.dot(a_h_2, self.w_out)\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        return z_h_1, a_h_1, z_h_2, a_h_2, z_out, a_out\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_cost(y_enc, output):  # Eq 4\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1.0 - y_enc) * np.log(1.0 - output)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        z_h_1, a_h_1, z_h_2, a_h_2, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        import sys\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "        #weights output\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, n_output))\n",
    "        #weights hidden layer 2\n",
    "        self.w_h_2 = self.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, self.n_hidden))\n",
    "        #weights hidden layer 1\n",
    "        self.w_h_1 = self.random.normal(loc=0.0, scale=0.1, size=(n_features, self.n_hidden))\n",
    "        y_train_enc = self.onehot(y_train, n_output)  # one-hot encode original y\n",
    "        for i in range(self.epochs):  # Ideally must shuffle at every epoch\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                z_h_1, a_h_1, z_h_2, a_h_2, z_out, a_out = self._forward(X_train[batch_idx])  # neural network model\n",
    "\n",
    "                #back propogation of error\n",
    "                #sigmoid der for a_h_1\n",
    "                sigmoid_derivative_h_1 = a_h_1 * (1.0 - a_h_1)  # Eq 3\n",
    "                #sigmoid der for a_h_2\n",
    "                sigmoid_derivative_h_2 = a_h_2 * (1.0 - a_h_2)  # Eq 3\n",
    "                delta_out = a_out - y_train_enc[batch_idx]  # Eq 5\n",
    "                #error at hidden layer\n",
    "                delta_h_2 = (np.dot(delta_out, self.w_out.T) * sigmoid_derivative_h_2)  # Eq 6\n",
    "                delta_h_1 = (np.dot(delta_h_2, self.w_h_2.T) * sigmoid_derivative_h_1)  # Eq 6\n",
    "                #gradient\n",
    "                grad_w_out = np.dot(a_h_2.T, delta_out)  # Eq 7\n",
    "                grad_w_h_2 = np.dot(a_h_1.T, delta_h_2)  # Eq 8\n",
    "                grad_w_h_1 = np.dot(X_train[batch_idx].T, delta_h_1)  # Eq 8\n",
    "                #update weights\n",
    "                self.w_out -= self.eta * grad_w_out  # Eq 9\n",
    "                self.w_h_2 -= self.eta * grad_w_h_2  # Eq 9\n",
    "                self.w_h_1 -= self.eta * grad_w_h_1  # Eq 9\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h_1, a_h_1, z_h_2, a_h_2, z_out, a_out = self._forward(X_train)\n",
    "            cost = self.compute_cost(y_enc=y_train_enc, output=a_out)\n",
    "            y_train_pred = self.predict(X_train)  # monitoring training progress through reclassification\n",
    "            y_valid_pred = self.predict(X_valid)  # monitoring training progress through validation\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(float) / X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(float) / X_valid.shape[0])\n",
    "            sys.stderr.write('\\r%d/%d | Cost: %.2f ' '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (i + 1, self.epochs, cost, train_acc * 100, valid_acc * 100))\n",
    "            sys.stderr.flush()\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23144998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300/300 | Cost: 14601.96 | Train/Valid Acc.: 96.29%/95.72% "
     ]
    }
   ],
   "source": [
    "# Define and fit the neural network\n",
    "nn = NeuralNetMLP(n_hidden=20, epochs=300, eta=0.0001, minibatch_size=1000, seed=1)\n",
    "\n",
    "nn.fit(X_train=X_train[:55000], y_train=y_train[:55000], X_valid=X_train[55000:], y_valid=y_train[55000:]) ;\n",
    "\n",
    "y_pred = nn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f6c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 94.80%\n",
      "[[ 960    0    1    1    3    5    7    1    2    0]\n",
      " [   0 1114    4    1    0    2    3    4    7    0]\n",
      " [  14    2  967    8   10    4    6   10   11    0]\n",
      " [   1    1   21  945    1   16    1    9   11    4]\n",
      " [   1    0    3    0  941    0    9    2    9   17]\n",
      " [  12    2    2   24    0  805   16    1   23    7]\n",
      " [   8    3    1    0    8    8  925    0    5    0]\n",
      " [   1    8   22    6    8    1    0  971    2    9]\n",
      " [   4    4    2   13    6   12    7    4  916    6]\n",
      " [   6    6    1   13   25    6    1    8    7  936]]\n"
     ]
    }
   ],
   "source": [
    "#get accuracy and confusion matrix\n",
    "print(f'Accuracy= {get_acc(y_test,y_pred)*100:.2f}%')\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498781a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
